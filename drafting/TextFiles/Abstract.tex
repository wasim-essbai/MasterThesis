Machine learning has been widely employed in several critical domains, often involving human interaction, such as autonomous driving and healthcare. These algorithms derive models from data without specific domain knowledge. Recent technological advancements have led to the spread of these complex models, enabling them to tackle intricate tasks across various fields. However, as model complexity grows, it becomes increasingly challenging to understand their internal workings, posing issues when faults occur and their causes become unclear. Consequently, ensuring model safety through validation is vital.
Generally, a model performance lies on the quality of its training data, meaning that if the data are not representative of the real world, the model may exhibit unexpected behavior with new data samples. This problem can manifest in real-world applications due to changes in the environment, system alterations, or data acquisition problems.

In this study, Bayesian Neural Networks (BNNs) are proposed as a promising framework for addressing these challenges, thanks to their capability to provide uncertainty estimates. The foundation of this framework is rooted in Bayesian probabilistic modeling, which allows for quantifying uncertainty in both model parameters and predictions. To achieve this, a comprehensive review of Bayesian inference methodologies and uncertainty estimation techniques is conducted.

The thesis further explores how leveraging uncertainty estimation can enhance the robustness of BNNs in an image classification task. Additionally, this research delves into the development of novel evaluation metrics and methodologies for BNNs, which take into account not only predictive performance but also the quality of uncertainty estimates. The proposed evaluation criteria assess the BNNs ability to offer calibrated and reliable uncertainty estimates, crucial factors for ensuring their robustness.

The final result is a systematic approach for evaluating the robustness of BNNs, including their handling of uncertainty. The performances of BNNs are compared to that of a standard neural network with the same architecture. The findings presented here lay the groundwork for future advancements in the field of uncertainty-aware machine learning, with implications for industries spanning healthcare, autonomous systems, and beyond.