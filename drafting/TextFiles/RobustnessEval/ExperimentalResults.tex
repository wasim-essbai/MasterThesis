\section{Robustness analysis}

After introducing the alterations to be applied to assess the model robustness, we generated altered datasets for each alteration. Specifically, we uniformly sampled 20 points from each alteration range. The subsequent step involves evaluating the networks on these altered datasets to compute the necessary metrics. For the standard NN, only accuracy is computed, whereas for the BNN, additional metrics include the unknown ratio and effectiveness. Moreover, the BNN metrics will be calculated using different classification methods introduced in \Chap~\ref{chap:c3}. The classification method with uncertainty penalization will not be used, as it has proven to be ineffective in this application.

As mentioned at the beginning of this chapter, the definition of robustness used is the one in \Def~\ref{def:rob3}, with linear tolerance, zero threshold, and a $maxAcc$ set to the nominal accuracy. Since $\Theta=0$, there is no penalization function, resulting in a metric ranging from $0.5$ in the worst-case scenario to $1$ in the best-case scenario.

For the BNN, robustness against indecision will also be computed based on \Def~\ref{def:robind}, employing a linear tolerance, $\gamma=100$, and the nominal unknown ratio as the baseline. Additionally, we will calculate augmented robustness following \Def~\ref{def:robaug}, which uses the effectiveness as well.

\import{./TextFiles/RobustnessEval/ExperimentalResults}{GaussianNoise.tex}
\import{./TextFiles/RobustnessEval/ExperimentalResults}{Blur.tex}
\import{./TextFiles/RobustnessEval/ExperimentalResults}{Brightness.tex}
\import{./TextFiles/RobustnessEval/ExperimentalResults}{HorizontalTranslation.tex}
\import{./TextFiles/RobustnessEval/ExperimentalResults}{VerticalTranslation.tex}
\import{./TextFiles/RobustnessEval/ExperimentalResults}{Compression.tex}
\import{./TextFiles/RobustnessEval/ExperimentalResults}{Zoom.tex}