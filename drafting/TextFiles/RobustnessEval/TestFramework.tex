\section{Test framework}

In this study, we employ a black-box testing approach, a techniques family designed to evaluate a model without any prior knowledge about its internal structure, relying solely on inputs and outputs behavior.
Consequently, an important aspect of this framework involves determining the significant inputs for the model. One effective approach is to precisely replicate the environment where the model will be deployed. Although this method can be effective, it may come with high setup costs. For example, in aerospace applications, replicating space conditions can be extremely expensive.
To address this challenge, our framework aims to simulate all possible operating conditions by identifying potential alterations to the input data. These perturbations must be carefully identified through an accurate domain analysis.
When dealing with NNs, it is possible to categorize inputs into two main classes:
\begin{itemize}
	\item Adversarial examples: These are perturbed input data intentionally created to arise errors from the model. Such inputs might not occur in real-world operating conditions. They are particularly valuable for assessing the robustness against external attacks;
	\item Natural inputs: These represent perturbed input data designed to simulate various conditions that can naturally occur in the real world. These inputs aim to simulate scenarios that the model may face during regular operations.
\end{itemize}

In this study, the primary focus is on natural inputs. However, it is important to note that the framework is versatile and can be applied to any set of alterations. Once defined the potential perturbations, the next step is to establish a reasonable range of intensities for these alterations. By instance, in an image classification task, one perturbation may be the brightness, which can happen within a specific intensity range.

For each identified alteration, a new dataset for each intensity level is generated by applying these transformations to the original data.

The following step involves selecting a robustness function and evaluating the model on the generated datasets to obtain the necessary metrics for computing robustness. It is worth noting that the obtained results should be compared against benchmarks to provide a meaningful assessment.
In summary, the framework can be outlined in the following steps:
\begin{enumerate}
	\item Domain analysis: Identify all possible alterations relevant to the problem domain;
	\item Intensity range definition: Determine suitable intensity ranges for each alteration;
	\item Altered data generation: Create altered datasets by applying transformations to the original data;
	\item Metrics and benchmark selection: Define the metrics to be used for the evaluation and establish benchmark criteria;
	\item Robustness definition: Choose an appropriate robustness function;
	\item Model evaluation: Assess the model performance on the altered datasets to compute the required metrics and calculate the robustness metric;
	\item Analysis and comparison: Analyze and compare the results to identify potential critical situations or areas of improvement.
\end{enumerate}

These steps form a systematic approach to comprehensively evaluate the robustness of a MLM.

In this study, we will apply the framework to evaluate two types of NNs: a standard NN and a BNN. The primary objective is to determine whether BNNs are more robustness than standard NNs. To ensure the metrics are comparable between the two models, we will employ the robustness function presented in \Def~\ref{def:rob3}, which is applicable to both cases. The performance of the standard NN will serve as a benchmark for evaluating the robustness of the BNN.

Since the implemented networks does not belong to any particular domain application, we will set the minimum acceptable accuracy to zero. This choice allows us to compute a robustness metric that is independent of the specific application. Consequently, only the tolerance function will be used, and it will be linear. The maximum accuracy will be selected to be equal to the one in the nominal conditions. This decision is intended to assess the network robustness only in terms of degradation when exposed to altered inputs, without being influenced by a specific use case.

Additionally, to ensure a fair comparison of robustness between various types of alterations, we will maintain a linear probability distribution of alteration levels for all the alteration types.

For the BNN, we will perform additional analyses. Specifically, for each alteration, we will apply classification without and with uncertainty to investigate whether there is an improvement in performance. Classification with uncertainty will be executed with a confidence level of $0.5$. Consequently, we will evaluate the BNN by computing both the robustness to indecision, as presented in \Def~\ref{def:robind}, and the augmented robustness introduced in \Def~\ref{def:rob3}. This analysis will allow us to determine whether the BNN can enhance robustness through the estimated uncertainty. Furthermore, different types of uncertainty will be employed, which will help in identifying the most effective approach.