@book{aggarwal2018neural,
  __markedentry = {[flint:2]},
  abstract = {This book covers both classical and modern models in deep learning. The primary focus is on the theory and algorithms of deep learning. The theory and algorithms of neural networks are particularly important for understanding important concepts, so that one can understand the important design concepts of neural architectures in different applications. Why do neural networks work? When do they work better than off-the-shelf machine-learning models? When is depth useful? Why is training neural networks so hard? What are the pitfalls? The book is also rich in discussing different applications in order to give the practitioner a flavor of how neural architectures are designed for different types of problems. Applications associated with many different areas like recommender systems, machine translation, image captioning, image classification, reinforcement-learning based gaming, and text analytics are covered. The chapters of this book span three categories. First, the basics of neural networks: Many traditional machine learning models can be understood as special cases of neural networks. An emphasis is placed in the first two chapters on understanding the relationship between traditional machine learning and neural networks. Support vector machines, linear/logistic regression, singular value decomposition, matrix factorization, and recommender systems are shown to be special cases of neural networks. These methods are studied together with recent feature engineering methods like word2vec. The second part deals with Fundamentals of neural networks: A detailed discussion of training and regularization is provided in Chapters 3 and 4. Chapters 5 and 6 present radial-basis function (RBF) networks and restricted Boltzmann machines. The final part covers Advanced topics in neural networks: Chapters 7 and 8 discuss recurrent neural networks and convolutional neural networks. Several advanced topics like deep reinforcement learning, neural Turing machines, Kohonen self-organizing maps, and generative adversarial networks are introduced in Chapters 9 and 10.},
  added-at = {2021-04-12T10:31:33.000+0200},
  address = {Cham},
  author = {Aggarwal, Charu C.},
  biburl = {https://www.bibsonomy.org/bibtex/26681a2e990d3d35887d519e2ec3bd7a9/sdo},
  doi = {10.1007/978-3-319-94463-0},
  file = {copy:201x/8/Aggarwal18.pdf:PDF;shop:https\://www.springer.com/978-3-319-94462-3:text/html;archive:https\://www.springerprofessional.de/neural-networks-and-deep-learning/16073524:text/html},
  gender = {sm},
  interhash = {59b0c6aa4a43b74401bca82051990b53},
  intrahash = {6681a2e990d3d35887d519e2ec3bd7a9},
  isbn = {978-3-319-94462-3},
  keywords = {deep learning},
  owner = {flint},
  pages = 497,
  publisher = {Springer},
  referencetype = {book},
  subtitle = {A Textbook},
  timestamp = {2021-04-12T10:31:33.000+0200},
  title = {Neural Networks and Deep Learning},
  x.asin = {3319944622},
  x.sortdate = {2018-09},
  year = 2018
}
@misc{APS,
	title = {Action potentials and synapses},
	howpublished = {\url{https://qbi.uq.edu.au/brain-basics/brain/brain-physiology/action-potentials-and-synapses#:~:text=Key%20facts%3A%20action%20potential%20and,to%20release%20a%20chemical%20neurotransmitter}}
}
@misc{WPBGP,
	title = {What is Perceptron: A Beginners Guide for Perceptron},
	howpublished = {\url{https://www.simplilearn.com/tutorials/deep-learning-tutorial/perceptron}}
}
@article{KANDEL2020312,
	title = {The effect of batch size on the generalizability of the convolutional neural networks on a histopathology dataset},
	journal = {ICT Express},
	volume = {6},
	number = {4},
	pages = {312-315},
	year = {2020},
	issn = {2405-9595},
	doi = {https://doi.org/10.1016/j.icte.2020.04.010},
	url = {https://www.sciencedirect.com/science/article/pii/S2405959519303455},
	author = {Ibrahem Kandel and Mauro Castelli},
}
@misc{CLFML,
	title = {Common Loss Functions in Machine Learning},
	howpublished = {\url{https://towardsdatascience.com/common-loss-functions-in-machine-learning-46af0ffc4d23}}
}
@misc{UIBASP,
	title = {Understand and Implement the Backpropagation Algorithm From Scratch In Python},
	howpublished = {\url{https://www.adeveloperdiary.com/data-science/machine-learning/understand-and-implement-the-backpropagation-algorithm-from-scratch-in-python/}}
}
@book{Goodfellow-et-al-2016,
  added-at = {2017-03-13T20:27:27.000+0100},
  author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  biburl = {https://www.bibsonomy.org/bibtex/2175f81afff897a68829e4d30c080a8fb/hotho},
  interhash = {62814dec510d5c55b0b38ad85a6c748d},
  intrahash = {175f81afff897a68829e4d30c080a8fb},
  keywords = {book deep learning toread},
  note = {Book in preparation for MIT Press},
  publisher = {MIT Press},
  timestamp = {2017-04-14T13:44:20.000+0200},
  title = {Deep Learning},
  url = {http://www.deeplearningbook.org},
  year = 2016
}
@misc{GDAWML,
	title = {How Does the Gradient Descent Algorithm Work in Machine Learning?},
	howpublished = {\url{https://www.analyticsvidhya.com/blog/2020/10/how-does-the-gradient-descent-algorithm-work-in-machine-learning/}}
}
@ARTICLE{9756596,
  author={Jospin, Laurent Valentin and Laga, Hamid and Boussaid, Farid and Buntine, Wray and Bennamoun, Mohammed},
  journal={IEEE Computational Intelligence Magazine}, 
  title={Hands-On Bayesian Neural Networks—A Tutorial for Deep Learning Users}, 
  year={2022},
  volume={17},
  number={2},
  pages={29-48},
  doi={10.1109/MCI.2022.3155327}
}
@book{James2013,
  added-at = {2019-10-12T20:03:56.000+0200},
  author = {James, Gareth and Witten, Daniela and Hastie, Trevor and Tibshirani, Robert},
  biburl = {https://www.bibsonomy.org/bibtex/2444186c86d18bddb4433c12fa126f6be/lopusz_kdd},
  interhash = {b3febabdc45a8629023cee7323dfbd86},
  intrahash = {444186c86d18bddb4433c12fa126f6be},
  keywords = {general_machine_learning},
  publisher = {Springer},
  timestamp = {2019-10-12T23:45:37.000+0200},
  title = {An Introduction to Statistical Learning: with Applications in R },
  url = {https://faculty.marshall.usc.edu/gareth-james/ISL/},
  year = 2013
}
@book{noauthororeditor,
  added-at = {2020-03-30T17:12:59.000+0200},
  author = {McElreath, Richard},
  biburl = {https://www.bibsonomy.org/bibtex/278338fb3be3f2c65e8309f4875299b90/kirk86},
  description = {Statistical_Rethinking_sample.pdf},
  interhash = {7b9e77b5b345deaa1fa27ce3c419e424},
  intrahash = {78338fb3be3f2c65e8309f4875299b90},
  keywords = {book stats},
  timestamp = {2020-03-30T17:15:46.000+0200},
  title = {Statistical Rethinking, A Course in R and Stan},
  url = {http://xcelab.net/rmpubs/rethinking/Statistical_Rethinking_sample.pdf},
  year = 2015
}
@misc{WYSUBNN,
	title = {Why You Should Use Bayesian Neural Network},
	howpublished = {\url{https://towardsdatascience.com/why-you-should-use-bayesian-neural-network-aaf76732c150}}
}
@misc{BIPMCMCV,
	title = {Why You Should Use Bayesian Neural Network},
	howpublished = {\url{https://towardsdatascience.com/bayesian-inference-problem-mcmc-and-variational-inference-25a8aa9bce29}}
}

@misc{VBPI,
	title = {Variational Bayesian phylogenetic inference},
	howpublished = {\url{https://matsen.fhcrc.org/general/2019/08/24/vbpi.html}}
}

@article{Han2019StatisticalII,
  title={Statistical Inference in Mean-Field Variational Bayes},
  author={Wei Han and Yun Yang},
  journal={arXiv: Statistics Theory},
  year={2019},
  url={https://api.semanticscholar.org/CorpusID:207870813}
}

@article{doi:10.1080/01621459.2017.1285773,
	author = {David M. Blei and Alp Kucukelbir and Jon D. McAuliffe},
	title = {Variational Inference: A Review for Statisticians},
	journal = {Journal of the American Statistical Association},
	volume = {112},
	number = {518},
	pages = {859-877},
	year  = {2017},
	doi = {10.1080/01621459.2017.1285773},
	URL = {https://doi.org/10.1080/01621459.2017.1285773	}
}

@inproceedings{Mitros2019OnTV,
  title={On the Validity of Bayesian Neural Networks for Uncertainty Estimation},
  author={John Mitros and Brian Mac Namee},
  booktitle={Irish Conference on Artificial Intelligence and Cognitive Science},
  year={2019},
  url={https://api.semanticscholar.org/CorpusID:208547807}
}

@article{article01,
	author = {Hüllermeier, Eyke and Waegeman, Willem},
	year = {2021},
	month = {03},
	pages = {},
	title = {Aleatoric and epistemic uncertainty in machine learning: an introduction to concepts and methods},
	volume = {110},
	journal = {Machine Learning},
	doi = {10.1007/s10994-021-05946-3}
}
@incollection{NEURIPS2019_9015,
	title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
	author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
	booktitle = {Advances in Neural Information Processing Systems 32},
	pages = {8024--8035},
	year = {2019},
	publisher = {Curran Associates, Inc.},
	url = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf}
}

@article{lecun-mnisthandwrittendigit-2010,
  added-at = {2010-06-28T21:16:30.000+0200},
  author = {LeCun, Yann and Cortes, Corinna},
  biburl = {https://www.bibsonomy.org/bibtex/2935bad99fa1f65e03c25b315aa3c1032/mhwombat},
  groups = {public},
  howpublished = {http://yann.lecun.com/exdb/mnist/},
  interhash = {21b9d0558bd66279df9452562df6e6f3},
  intrahash = {935bad99fa1f65e03c25b315aa3c1032},
  keywords = {MSc _checked character_recognition mnist network neural},
  lastchecked = {2016-01-14 14:24:11},
  timestamp = {2016-07-12T19:25:30.000+0200},
  title = {{MNIST} handwritten digit database},
  url = {http://yann.lecun.com/exdb/mnist/},
  username = {mhwombat},
  year = 2010
}

@misc{OMBGD,
	title = {Overview of mini-batch gradient descent},
	howpublished = {\url{https://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf}}
}

@misc{CELoss,
	title = {CROSSENTROPYLOSS},
	howpublished = {\url{https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html}}
}

@misc{mao2023crossentropy,
      title={Cross-Entropy Loss Functions: Theoretical Analysis and Applications}, 
      author={Anqi Mao and Mehryar Mohri and Yutao Zhong},
      year={2023},
      eprint={2304.07288},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{Torchbnn,
	title = {Torchbnn},
	howpublished = {\url{https://bayesian-neural-network-pytorch.readthedocs.io/en/latest/index.html}}
}

@article{KWON2020106816,
	title = {Uncertainty quantification using Bayesian neural networks in classification: Application to biomedical image segmentation},
	journal = {Computational Statistics and Data Analysis},
	volume = {142},
	pages = {106816},
	year = {2020},
	issn = {0167-9473},
	doi = {https://doi.org/10.1016/j.csda.2019.106816},
	url = {https://www.sciencedirect.com/science/article/pii/S016794731930163X},
	author = {Yongchan Kwon and Joong-Ho Won and Beom Joon Kim and Myunghee Cho Paik}
}